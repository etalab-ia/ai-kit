{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# Compliance Documentation: French Government FAQ Chatbot\n",
    "\n",
    "**Category**: compliance\n",
    "**Purpose**: EU AI Act compliance documentation for high-risk AI system - automated chatbot for French government services\n",
    "**Author**: Compliance Team\n",
    "**Created**: 2024-10-15\n",
    "\n",
    "**Data Sources**:\n",
    "- Training dataset: `data/faq-training-v2.csv` (10,000 Q&A pairs, collected 2023-2024)\n",
    "- Validation dataset: `data/faq-validation-v2.csv` (2,000 Q&A pairs)\n",
    "- Bias assessment data: `data/demographic-distribution.csv` (user demographics)\n",
    "- Performance logs: `logs/chatbot-production-2024-q3.jsonl`\n",
    "\n",
    "**Dependencies**:\n",
    "```\n",
    "# Compliance analysis tools\n",
    "pandas>=2.1.0\n",
    "numpy>=1.24.0\n",
    "matplotlib>=3.8.0\n",
    "scikit-learn>=1.3.0  # For fairness metrics\n",
    "```\n",
    "\n",
    "**Regulatory Context**:\n",
    "- Framework: EU AI Act\n",
    "- Risk level: **High-risk** (Annex III - Essential public services)\n",
    "- Review date: 2024-10-15\n",
    "- Reviewer: Marie Dubois (Compliance Officer)\n",
    "\n",
    "**EU AI Act Classification**:\n",
    "- [x] High-risk AI system (Annex III)\n",
    "- [ ] Limited risk (transparency obligations)\n",
    "- [ ] Minimal risk (no specific obligations)\n",
    "\n",
    "If high-risk, specify category:\n",
    "- [ ] Biometric identification\n",
    "- [ ] Critical infrastructure\n",
    "- [ ] Education/vocational training\n",
    "- [ ] Employment/worker management\n",
    "- [x] Essential services (public service access, benefits eligibility)\n",
    "- [ ] Law enforcement\n",
    "- [ ] Migration/asylum/border control\n",
    "- [ ] Administration of justice\n",
    "\n",
    "**System Description**:\n",
    "This AI system provides automated responses to citizen inquiries about French government services, including benefits eligibility, document requirements, and procedural guidance. The system is deployed on service-public.fr and handles ~50,000 queries per month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f1678",
   "metadata": {},
   "source": [
    "## EU AI Act Compliance Checklist\n",
    "\n",
    "### Article 9: Risk Management System\n",
    "\n",
    "- [ ] Risk management system established and documented\n",
    "- [ ] Risks identified and analyzed (including bias, discrimination)\n",
    "- [ ] Risk mitigation measures implemented\n",
    "- [ ] Residual risks evaluated and documented\n",
    "- [ ] Testing procedures defined\n",
    "\n",
    "### Article 10: Data and Data Governance\n",
    "\n",
    "- [ ] Training data documented (sources, characteristics, biases)\n",
    "- [ ] Data quality criteria established\n",
    "- [ ] Data governance practices documented\n",
    "- [ ] Bias detection and mitigation measures in place\n",
    "- [ ] Data representativeness assessed\n",
    "\n",
    "### Article 11: Technical Documentation\n",
    "\n",
    "- [ ] System description and intended purpose documented\n",
    "- [ ] Design specifications and architecture documented\n",
    "- [ ] Data requirements and characteristics documented\n",
    "- [ ] Computational resources documented\n",
    "- [ ] Validation and testing procedures documented\n",
    "\n",
    "### Article 12: Record-Keeping\n",
    "\n",
    "- [ ] Automatic logging of events implemented\n",
    "- [ ] Log retention period defined\n",
    "- [ ] Traceability throughout lifecycle ensured\n",
    "\n",
    "### Article 13: Transparency and User Information\n",
    "\n",
    "- [ ] Users informed of AI system interaction\n",
    "- [ ] System capabilities and limitations communicated\n",
    "- [ ] Instructions for use provided\n",
    "\n",
    "### Article 14: Human Oversight\n",
    "\n",
    "- [ ] Human oversight measures defined\n",
    "- [ ] Override mechanisms implemented\n",
    "- [ ] Monitoring procedures established\n",
    "\n",
    "### Article 15: Accuracy, Robustness, Cybersecurity\n",
    "\n",
    "- [ ] Accuracy metrics defined and measured\n",
    "- [ ] Robustness testing performed\n",
    "- [ ] Cybersecurity measures implemented\n",
    "- [ ] Error handling procedures defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Training Data Characteristics\n",
    "\n",
    "**EU AI Act Article 10 Requirements**\n",
    "\n",
    "Document the following for training datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c42bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Documentation (EU AI Act Article 10)\n",
    "\n",
    "\n",
    "# Load training data\n",
    "# training_data = pd.read_csv('data/training-data.csv')\n",
    "\n",
    "# Dataset characteristics\n",
    "dataset_info = {\n",
    "    \"size\": \"Number of samples\",\n",
    "    \"features\": \"Number and types of features\",\n",
    "    \"collection_period\": \"When data was collected\",\n",
    "    \"geographic_scope\": \"Geographic coverage\",\n",
    "    \"demographic_representation\": \"Demographics represented\",\n",
    "}\n",
    "\n",
    "# Data quality assessment\n",
    "quality_metrics = {\n",
    "    \"completeness\": \"Percentage of complete records\",\n",
    "    \"accuracy\": \"Data validation results\",\n",
    "    \"consistency\": \"Cross-field validation\",\n",
    "    \"timeliness\": \"Data freshness\",\n",
    "}\n",
    "\n",
    "# Bias assessment\n",
    "bias_analysis = {\n",
    "    \"demographic_distribution\": \"Distribution across protected attributes\",\n",
    "    \"label_distribution\": \"Class balance analysis\",\n",
    "    \"known_biases\": \"Identified biases in source data\",\n",
    "    \"mitigation_measures\": \"Steps taken to address biases\",\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "print(\"Training Data Characteristics:\")\n",
    "print(\"  Dataset size: [X samples]\")\n",
    "print(\"  Features: [X features]\")\n",
    "print(\"  Collection period: [YYYY-MM to YYYY-MM]\")\n",
    "print(\"\\nBias Assessment:\")\n",
    "print(\"  Protected attributes analyzed: [age, gender, ethnicity, etc.]\")\n",
    "print(\"  Identified biases: [list]\")\n",
    "print(\"  Mitigation measures: [list]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document training data characteristics\n",
    "\n",
    "# Load and analyze training data\n",
    "# training_data = pd.read_csv('data/training-data.csv')\n",
    "# print(f'Dataset size: {len(training_data)}')\n",
    "# print(f'Features: {training_data.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## Risk Assessment Findings\n",
    "\n",
    "**EU AI Act Article 9 Requirements**\n",
    "\n",
    "### Risk Categories\n",
    "\n",
    "**1. Fundamental Rights Risks**\n",
    "- Privacy violations\n",
    "- Discrimination/bias\n",
    "- Freedom of expression\n",
    "- Human dignity\n",
    "\n",
    "**2. Health and Safety Risks**\n",
    "- Physical harm\n",
    "- Psychological harm\n",
    "- Property damage\n",
    "\n",
    "**3. Operational Risks**\n",
    "- System failure\n",
    "- Incorrect outputs\n",
    "- Security vulnerabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "source": [
    "### Identified Risks\n",
    "\n",
    "| Risk ID | Description | Severity | Likelihood | Impact | Mitigation |\n",
    "|---------|-------------|----------|------------|--------|------------|\n",
    "| R-001   | [Risk description] | High/Medium/Low | High/Medium/Low | [Impact description] | [Mitigation measures] |\n",
    "| R-002   | [Risk description] | High/Medium/Low | High/Medium/Low | [Impact description] | [Mitigation measures] |\n",
    "\n",
    "### Mitigation Measures\n",
    "\n",
    "**Technical Measures**:\n",
    "1. [Measure 1]: [Implementation details]\n",
    "2. [Measure 2]: [Implementation details]\n",
    "\n",
    "**Organizational Measures**:\n",
    "1. [Measure 1]: [Implementation details]\n",
    "2. [Measure 2]: [Implementation details]\n",
    "\n",
    "**Human Oversight Measures**:\n",
    "1. [Measure 1]: [Implementation details]\n",
    "2. [Measure 2]: [Implementation details]\n",
    "\n",
    "### Residual Risks\n",
    "\n",
    "After mitigation:\n",
    "- [Residual risk 1]: [Acceptance rationale]\n",
    "- [Residual risk 2]: [Acceptance rationale]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## Model Selection Audit Trail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "source": [
    "### Models Considered\n",
    "1. [Model 1]: [Rationale for consideration/rejection]\n",
    "2. [Model 2]: [Rationale for consideration/rejection]\n",
    "\n",
    "### Selected Model\n",
    "- Model: [Selected model]\n",
    "- Rationale: [Why this model was chosen]\n",
    "- Trade-offs: [Acknowledged trade-offs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "## Validation & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document validation results\n",
    "# Reference evaluation notebook: notebooks/evaluations/[evaluation-notebook].ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875dfb2",
   "metadata": {},
   "source": [
    "## Human Oversight (Article 14)\n",
    "\n",
    "### Oversight Measures\n",
    "\n",
    "**Human-in-the-Loop**:\n",
    "- [ ] Human reviews each decision before execution\n",
    "- Description: [How humans are involved]\n",
    "\n",
    "**Human-on-the-Loop**:\n",
    "- [ ] Human can intervene during operation\n",
    "- Description: [Monitoring and intervention procedures]\n",
    "\n",
    "**Human-in-Command**:\n",
    "- [ ] Human can override system at any time\n",
    "- Description: [Override mechanisms]\n",
    "\n",
    "### Monitoring Procedures\n",
    "\n",
    "- Monitoring frequency: [Continuous/Daily/Weekly]\n",
    "- Metrics monitored: [List key metrics]\n",
    "- Alert thresholds: [Define when human intervention required]\n",
    "- Escalation procedures: [Who to contact, when]\n",
    "\n",
    "### Training Requirements\n",
    "\n",
    "- Personnel training: [Required training for operators]\n",
    "- Documentation: [User manuals, SOPs]\n",
    "- Competency assessment: [How competency is verified]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf454a12",
   "metadata": {},
   "source": [
    "## Accuracy, Robustness, Cybersecurity (Article 15)\n",
    "\n",
    "### Accuracy Metrics\n",
    "\n",
    "| Metric | Target | Achieved | Test Set |\n",
    "|--------|--------|----------|----------|\n",
    "| Accuracy | ≥X% | Y% | [Test set description] |\n",
    "| Precision | ≥X% | Y% | [Test set description] |\n",
    "| Recall | ≥X% | Y% | [Test set description] |\n",
    "| F1 Score | ≥X | Y | [Test set description] |\n",
    "\n",
    "Reference: `notebooks/evaluations/[evaluation-notebook].ipynb`\n",
    "\n",
    "### Robustness Testing\n",
    "\n",
    "**Adversarial Testing**:\n",
    "- [ ] Tested against adversarial inputs\n",
    "- Results: [Summary of robustness]\n",
    "\n",
    "**Edge Cases**:\n",
    "- [ ] Tested with edge cases and boundary conditions\n",
    "- Results: [Summary of edge case handling]\n",
    "\n",
    "**Data Distribution Shifts**:\n",
    "- [ ] Tested with out-of-distribution data\n",
    "- Results: [Summary of generalization]\n",
    "\n",
    "### Cybersecurity Measures\n",
    "\n",
    "**Access Control**:\n",
    "- Authentication: [Methods used]\n",
    "- Authorization: [Role-based access control]\n",
    "- Audit logging: [What is logged]\n",
    "\n",
    "**Data Protection**:\n",
    "- Encryption at rest: [Yes/No, method]\n",
    "- Encryption in transit: [Yes/No, method]\n",
    "- Data anonymization: [Methods used]\n",
    "\n",
    "**System Security**:\n",
    "- Vulnerability scanning: [Frequency, tools]\n",
    "- Penetration testing: [Last performed, results]\n",
    "- Incident response: [Procedures in place]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": [
    "## Compliance Officer Review\n",
    "\n",
    "**Review Checklist**:\n",
    "- [ ] All EU AI Act requirements addressed\n",
    "- [ ] Risk assessment complete and adequate\n",
    "- [ ] Training data properly documented\n",
    "- [ ] Human oversight measures defined\n",
    "- [ ] Accuracy and robustness verified\n",
    "- [ ] Technical documentation complete\n",
    "\n",
    "**Review Decision**:\n",
    "- [ ] Approved for production deployment\n",
    "- [ ] Approved with conditions: [List conditions]\n",
    "- [ ] Rejected - requires updates: [List required updates]\n",
    "\n",
    "**Reviewer**: [Name]\n",
    "**Review Date**: [YYYY-MM-DD]\n",
    "**Next Review Date**: [YYYY-MM-DD]\n",
    "\n",
    "After approval, create git tag:\n",
    "```bash\n",
    "just notebook tag notebooks/compliance/[this-notebook].ipynb \\\n",
    "  --identifier [system]-[version]-audit \\\n",
    "  --message \"EU AI Act compliance approved by [Reviewer Name]\" \\\n",
    "  --push\n",
    "```\n",
    "\n",
    "**Tag Reference**: [Will be filled after tagging]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
